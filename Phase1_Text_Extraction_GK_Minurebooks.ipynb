{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phase1-Text-Extraction_GK_Minurebooks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnc2TVu5WgjZ"
      },
      "source": [
        "## 1. This notebook takes a PDF file as input and outputs extracted text as a .txt file \n",
        "\n",
        "## 2. Extractor used: PyPDF2 , can be extended for any other extractor like pyMuPDF, AWS textract , tesseract OCR extractor  \n",
        "\n",
        "## 3. The output shows the text per page and is saved to a list / dataframe / file under the directory you specify in save_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL5bdkDAW9cJ",
        "outputId": "b4be42e9-3558-47dd-ba7d-d0ce1946d462"
      },
      "source": [
        "#installations - this will later go t a requirements.txt file \n",
        "!apt-get update\n",
        "!uname -a\n",
        "#!pip install pypdf2\n",
        "!pip install PyMuPDF\n",
        "#!pip install boto3\n",
        "# Setup for Extraction of unstructured text data\n",
        "# Update my Google Colab and Install Textract Library\n",
        "#!apt-get install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils \\\n",
        "#pstotext tesseract-ocr \\\n",
        "#flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig libasound2-dev libpulse-dev\n",
        "#!pip install git+https://github.com/deanmalmgren/textract\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.38)] [Connected to cloud.r-pro\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r                                                                               \rHit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Wa\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r0% [1 InRelease gpgv 242 kB] [6 InRelease 40.3 kB/74.6 kB 54%] [Connecting to s\r0% [1 InRelease gpgv 242 kB] [Connecting to security.ubuntu.com (91.189.91.38)]\r                                                                               \rHit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [575 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,199 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,730 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,792 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [917 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,424 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,294 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB]\n",
            "Fetched 12.8 MB in 4s (3,484 kB/s)\n",
            "Reading package lists... Done\n",
            "Linux 14fe7e5a9d03 5.4.104+ #1 SMP Sat Jun 5 09:50:34 PDT 2021 x86_64 x86_64 x86_64 GNU/Linux\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.18.16-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 12.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.18.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i1PFqbY8DaF"
      },
      "source": [
        "You have to mount your drive using your gmail credentials "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeXDDXZbXbSq",
        "outputId": "43758335-08f6-4b99-c936-424bbb340a70"
      },
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "844neArFXX66"
      },
      "source": [
        "#imports\n",
        "import os \n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import sys\n",
        "import fitz# or any other library we plan to use instead of PyPDF2\n",
        "#import textract\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLj4tPxfdAsu"
      },
      "source": [
        "#functions\n",
        "def listToString(s): \n",
        "    # initialize an empty string\n",
        "    str1 = \"\" \n",
        "    # traverse in the string  \n",
        "    for ele in s: \n",
        "      str1 += ele\n",
        "    # return string  \n",
        "    return str1 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNMvS5fb8s47"
      },
      "source": [
        "Change base_path and save_path to the folder where you have your source pdfs stored "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-n358tEEYg9n",
        "outputId": "c769834f-5a0a-402c-e065-7dd2cb8cdfc5"
      },
      "source": [
        "#os\n",
        "base_path = '/content/drive/MyDrive/week6'#change this to the folder in Drive where you have your source pdf stored \n",
        "save_path = '/content/drive/MyDrive/week6'#change this tothe folder in Drive where you plan to store the extracted text \n",
        "os.chdir(base_path)\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/week6'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS9Q07T-9juU"
      },
      "source": [
        "Enter the file name and click on run "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTeEA4svYn93"
      },
      "source": [
        "os.listdir()\n",
        "#for now, pick one file to work with \n",
        "#@title String fields\n",
        "text = 'pdf5.pdf' #@param {type:\"string\"}\n",
        "filenames = text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FvpFpJxq9b78",
        "outputId": "683823a8-f48d-4c25-c18a-d68c4f711af9"
      },
      "source": [
        "filenames"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pdf5.pdf'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUU43Mrxbu94"
      },
      "source": [
        "pdf_path= os.path.join(base_path, filenames)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYHEu0eTLTZX"
      },
      "source": [
        "Fitz "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVUsRk9zKeT2"
      },
      "source": [
        "doc = fitz.open(filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8vQpzekLeZd"
      },
      "source": [
        "Document.page_count\tthe number of pages (int)\n",
        "\n",
        "Document.metadata\tthe metadata (dict)\n",
        "\n",
        "Document.get_toc()\tget the table of contents (list)\n",
        "\n",
        "Document.load_page()\tread a Page\n",
        "\n",
        "Document.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xycPeS47MXps"
      },
      "source": [
        "“text”: (default) plain text with line breaks. No formatting, no text position details, no images.\n",
        "“blocks”: generate a list of text blocks (= paragraphs).\n",
        "“words”: generate a list of words (strings not containing spaces).\n",
        "“html”: creates a full visual version of the page including any images. This can be displayed with your internet browser.\n",
        "“dict” / “json”: same information level as HTML, but provided as a Python dictionary or resp. JSON string. See TextPage.extractDICT() for details of its structure.\n",
        "“rawdict” / “rawjson”: a super-set of “dict” / “json”. It additionally provides character detail information like XML. See TextPage.extractRAWDICT() for details of its structure.\n",
        "“xhtml”: text information level as the TEXT version but includes images. Can also be displayed by internet browsers.\n",
        "“xml”: contains no images, but full position and font information down to each single text character. Use an XML module to interpret."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmBS9xXMLVMW"
      },
      "source": [
        "import sys, fitz\n",
        "fname = filenames  # get document filename\n",
        "doc = fitz.open(fname)  # open document\n",
        "out_file = fname + \"_fitz\"\n",
        "out = open(out_file + \".txt\", \"wb\")  # open text output\n",
        "for page in doc:  # iterate the document pages\n",
        "    text = page.get_text().encode(\"utf8\")  # get plain text (is in UTF-8)\n",
        "    out.write(text)  # write text of page\n",
        "    out.write(bytes((12,)))  # write page delimiter (form feed 0x0C)\n",
        "out.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gi5E_iMNusk"
      },
      "source": [
        "For future - Extract text as a list of text blocks via Page.get_text(“blocks”)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uXv_8Zn92KU"
      },
      "source": [
        "The file is saved to the save_path specified above to a file extracted_pypdf2_pdf5.txt\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGVbG4xt_407"
      },
      "source": [
        "The text file will be used in the next notebook Phase2_spacy_extract_variables\n",
        "\n",
        "Check your saved file by runnning the cell below "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HZsGdIhWfr4",
        "outputId": "2ffa9db3-f823-4f25-eccd-06483c4c1efd"
      },
      "source": [
        "os.listdir(save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['programming-fundamentals.pdf',\n",
              " 'spacy_ner_entire_text_1pdf.ipynb',\n",
              " 'pdf5.pdf',\n",
              " 'extracted_pypdf2_pdf5.txt',\n",
              " 'spacy',\n",
              " 'extracted_programming-fundamentals.txt',\n",
              " 'Phase1-Text-Extraction_GK.ipynb',\n",
              " 'companies.json',\n",
              " 'ent.csv',\n",
              " 'iphone.json',\n",
              " 'sample-minutebook.pdf',\n",
              " 'extracted_pypdf2_pdf1_amend.txt',\n",
              " 'Copy of Phase2_spacy_extract_variables_GK.ipynb',\n",
              " 'entity_metrics_annotation_formats.gdoc',\n",
              " 'sas_model',\n",
              " 'sample-minutebook.pdf.txt',\n",
              " 'sample-minutebook (1).pdf.gdoc',\n",
              " 'sample-minutebook.pdf.gdoc',\n",
              " 'sas',\n",
              " 'generating_training_data.gdoc',\n",
              " 'Phase2_spacy_extract_variables_GK.ipynb',\n",
              " 'Phase1-Text-Extraction_GK_Minurebooks.ipynb',\n",
              " 'pdf5.pdf_fitz.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}